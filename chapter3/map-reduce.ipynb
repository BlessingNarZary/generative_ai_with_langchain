{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73104a06-9e3c-4594-8940-7234d79c274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the environment variables\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from config import set_environment\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526aee24-f911-4239-ac86-1ec75170214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/anaconda3/envs/newgen/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis article discusses the limitations of large language models (LLMs) and introduces a solution called Corrective Retrieval Augmented Generation (CRAG). CRAG uses a lightweight retrieval evaluator and web searches to improve the accuracy and robustness of LLMs in generating texts. It also includes a decompose-then-recompose algorithm to filter out irrelevant information. Experiments show that CRAG significantly improves the performance of retrieval-augmented generation approaches. It also discusses the issue of hallucinations in LLMs and how CRAG can help mitigate this problem. The article also references other related studies and papers in the field of retrieval-augmented text generation and LLMs. Finally, it presents the evaluation and results of CRAG on four datasets and compares it to other baseline models.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "pdf_file_path = \"https://arxiv.org/pdf/2401.15884.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "docs = pdf_loader.load_and_split()\n",
    "llm = OpenAI()\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ed41ea-138a-4826-9f74-329a85a7281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "\n",
      "This article discusses the limitations of large language models (LLMs) and introduces a solution called Corrective Retrieval Augmented Generation (CRAG). CRAG uses a lightweight retrieval evaluator and web searches to improve the accuracy and robustness of LLMs in generating texts. It also includes a decompose-then-recompose algorithm to filter out irrelevant information. Experiments show that CRAG significantly improves the performance of retrieval-augmented generation approaches. It also discusses the issue of hallucinations in LLMs and how CRAG can help mitigate this problem. The article also references other related studies and papers in the field of retrieval-augmented text generation and LLMs. Finally, it presents the evaluation and results of CRAG on four datasets and compares it to other baseline models.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"'\\n\\nThis article discusses the limitations of large language models (LLMs) and introduces a solution called Corrective Retrieval Augmented Generation (CRAG). CRAG uses a lightweight retrieval evaluator and web searches to improve the accuracy and robustness of LLMs in generating texts. It also includes a decompose-then-recompose algorithm to filter out irrelevant information. Experiments show that CRAG significantly improves the performance of retrieval-augmented generation approaches. It also discusses the issue of hallucinations in LLMs and how CRAG can help mitigate this problem. The article also references other related studies and papers in the field of retrieval-augmented text generation and LLMs. Finally, it presents the evaluation and results of CRAG on four datasets and compares it to other baseline models.'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca675ca-81fb-4d72-8f04-14a369759bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
